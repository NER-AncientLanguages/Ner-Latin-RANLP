{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latin-BERT training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 12 12:37:13 2023       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 3090         Off| 00000000:01:00.0 Off |                  N/A |\r\n",
      "| 30%   27C    P8               26W / 350W|      0MiB / 24576MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA GeForce RTX 3090         Off| 00000000:41:00.0 Off |                  N/A |\r\n",
      "| 30%   26C    P8               30W / 350W|      0MiB / 24576MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   2  NVIDIA GeForce RTX 3090         Off| 00000000:81:00.0 Off |                  N/A |\r\n",
      "| 30%   26C    P8               20W / 350W|      0MiB / 24576MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "|   3  NVIDIA GeForce RTX 3090         Off| 00000000:C1:00.0 Off |                  N/A |\r\n",
      "| 30%   25C    P8               29W / 350W|      0MiB / 24576MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|  No running processes found                                                           |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "# !pip install transformers\n",
    "# !pip install tensorflow\n",
    "# !pip install tensor2tensor\n",
    "# !pip install cltk\n",
    "# !pip install seqeval\n",
    "# !pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('./data/Latin_NER_train.csv', index_col=0)\n",
    "test = pd.read_csv('./data/Latin_NER_test.csv', index_col=0)\n",
    "val = pd.read_csv('./data/Latin_NER_eval.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O         82696\n",
       "B-PERS     2706\n",
       "B-GRP      1271\n",
       "B-LOC       839\n",
       "I-PERS      618\n",
       "I-LOC        31\n",
       "I-GRP         4\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "label2idx = {'O': 0, \n",
    " 'B-PERS': 1, \n",
    " 'I-PERS': 2, \n",
    " 'B-LOC': 3, \n",
    " 'I-LOC': 4, \n",
    " 'B-GRP': 5, \n",
    " 'I-GRP': 6}\n",
    "\n",
    "idx2label = {value: key for key, value in label2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/pricie/marijkeb/.cache/huggingface/datasets/json/Latin_NER_json-d0854115d27feb27/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0559ccb2f6403c8907cf3a2bd5b892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('data/Latin_NER_json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preparing the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download nessecary cltk models\n",
    "# !pip install cltk\n",
    "# import cltk\n",
    "# from cltk.data.fetch import FetchCorpus\n",
    "# corpus_downloader = FetchCorpus(language='lat')\n",
    "# corpus_downloader.import_corpus('lat_models_cltk')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 12:37:32.291555: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-12 12:37:35.768654: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# install tensor to tensor encoder\n",
    "# !pip install tensor2tensor --user\n",
    "# !pip install tensorflow\n",
    "\n",
    "# from cltk.tokenizers.lat.lat import LatinWordTokenizer as WordTokenizer\n",
    "# from cltk.tokenizers.lat.lat import LatinPunktSentenceTokenizer as SentenceTokenizer\n",
    "from tensor2tensor.data_generators import text_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copied this class and function from the latin-BERT repo\n",
    "#[REDACTED]'s code\n",
    "#made some adjustments\n",
    "\n",
    "from transformers import BatchEncoding\n",
    "\n",
    "class LatinTokenizer():\n",
    "\tdef __init__(self, encoder):\n",
    "\t\tself.vocab={}\n",
    "\t\tself.reverseVocab={}\n",
    "\t\tself.encoder=encoder\n",
    "\n",
    "\t\tself.vocab[\"[PAD]\"]=0\n",
    "\t\tself.vocab[\"[UNK]\"]=1\n",
    "\t\tself.vocab[\"[CLS]\"]=2\n",
    "\t\tself.vocab[\"[SEP]\"]=3\n",
    "\t\tself.vocab[\"[MASK]\"]=4\n",
    "\t\tself.model_max_length=256\n",
    "\t\tself.is_fast=False\n",
    "\n",
    "\n",
    "\t\tself.cls_token_id = self.vocab[\"[CLS]\"]\n",
    "\t\tself.pad_token_id = self.vocab[\"[PAD]\"]\n",
    "\t\tself.sep_token_id = self.vocab[\"[SEP]\"]\n",
    "        \n",
    "\t\tfor key in self.encoder._subtoken_string_to_id:\n",
    "\t\t\tself.vocab[key]=self.encoder._subtoken_string_to_id[key]+5\n",
    "\t\t\tself.reverseVocab[self.encoder._subtoken_string_to_id[key]+5]=key\n",
    "\n",
    "\n",
    "\tdef convert_tokens_to_ids(self, tokens):\n",
    "\t\twp_tokens=[]\n",
    "\t\tfor token in tokens:\n",
    "\t\t\tif token == \"[PAD]\":\n",
    "\t\t\t\twp_tokens.append(0)\n",
    "\t\t\telif token == \"[UNK]\":\n",
    "\t\t\t\twp_tokens.append(1)\n",
    "\t\t\telif token == \"[CLS]\":\n",
    "\t\t\t\twp_tokens.append(2)\n",
    "\t\t\telif token == \"[SEP]\":\n",
    "\t\t\t\twp_tokens.append(3)\n",
    "\t\t\telif token == \"[MASK]\":\n",
    "\t\t\t\twp_tokens.append(4)\n",
    "\n",
    "\t\t\telse:\n",
    "\t\t\t\twp_tokens.append(self.vocab[token])\n",
    "\n",
    "\t\treturn wp_tokens\n",
    "\n",
    "\tdef tokenize(self, text, split_on_tokens=True):\n",
    "\t\tif split_on_tokens:\n",
    "\t\t\ttokens = [token.lower() if token not in [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"] else token for token in text]\n",
    "\t\telse: \n",
    "\t\t\ttokens = text.split()\n",
    "\n",
    "\t\twp_tokens=[] #word-piece tokens\n",
    "\n",
    "\t\tfor token in tokens:\n",
    "\t\t\t# print(token)\n",
    "\n",
    "\t\t\tif token in {\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"}:\n",
    "\t\t\t\twp_tokens.append(token)\n",
    "\t\t\telse:\n",
    "\n",
    "\t\t\t\twp_toks=self.encoder.encode(token)\n",
    "\n",
    "\t\t\t\tfor wp in wp_toks:\n",
    "\t\t\t\t\twp_tokens.append(self.reverseVocab[wp+5])\n",
    "\n",
    "\t\treturn wp_tokens\n",
    "\t\n",
    "\tdef calculate_attention_masks(self, wp_tokens):\n",
    "\t\tattention_masks = []\n",
    "\t\t\n",
    "\t\tfor token in wp_tokens:\n",
    "\t\t\tif token == self.pad_token_id:\n",
    "\t\t\t\tattention_masks.append(0)\n",
    "\t\t\telse:\n",
    "\t\t\t\tattention_masks.append(1)\n",
    "\t\t\t\t\n",
    "\t\treturn attention_masks\n",
    "\t\n",
    "\tdef pad(self, features, padding=True, max_length=256, pad_to_multiple_of=\"\", return_tensors=True):\n",
    "\t\t# TODO\n",
    "\t\tbatch_outputs = {}\n",
    "\t\t\n",
    "\t\tfor i in range(len(features)):\n",
    "\t\t\tfor key, value in features[i].items():\n",
    "\t\n",
    "\t\t\t\tif key in batch_outputs:\n",
    "\t\t\t\t\tbatch_outputs[key].append(value)\n",
    "\t\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tbatch_outputs[key] = [value]\n",
    "\n",
    "\t\tfor k, v in batch_outputs.items():\n",
    "\t\t\tbatch_outputs[k] = torch.tensor([x for x in v])\n",
    "\n",
    "\t\treturn BatchEncoding(batch_outputs)\n",
    "\t\n",
    "\tdef pad_max_length_and_add_specials_tokens_also(self, tokens, wp_tokens):\n",
    "\n",
    "\t\tMAX_LENGTH = 256\n",
    "\t\twp_tokens.insert(0, self.cls_token_id)\n",
    "\t\ttokens.insert(0, '[CLS]')\n",
    "\t\twp_tokens.append(self.sep_token_id)\n",
    "\t\ttokens.append('[SEP]')\n",
    "\t\t\n",
    "\t\tif len(wp_tokens) > 256:\n",
    "\t\t\twp_tokens = wp_tokens[:256]\n",
    "\t\t\ttokens = tokens[:256]\n",
    "\t\t\n",
    "\t\telse:\n",
    "\t\t\twhile len(wp_tokens) < 256:\n",
    "\t\t\t\twp_tokens.append(self.pad_token_id)\n",
    "\t\t\t\ttokens.append('[PAD]')\n",
    "\n",
    "\t\treturn tokens, wp_tokens\n",
    "\t\n",
    "\tdef pad_max_length_and_add_specials(self, wp_tokens):\n",
    "\n",
    "\t\tMAX_LENGTH = 256\n",
    "\t\twp_tokens.insert(0, self.cls_token_id)\n",
    "\t\twp_tokens.append(self.sep_token_id)\n",
    "\t\t\n",
    "\t\tif len(wp_tokens) > 256:\n",
    "\t\t\twp_tokens = wp_tokens[:256]\n",
    "\t\t\n",
    "\t\telse:\n",
    "\t\t\twhile len(wp_tokens) < 256:\n",
    "\t\t\t\twp_tokens.append(self.pad_token_id)\n",
    "\n",
    "\t\treturn wp_tokens\n",
    "\t\n",
    "\tdef decode_to_string(self, input_ids):\n",
    "\t\ttokens = [self.reverseVocab[x] for x in input_ids if x > 4]\n",
    "\t\treturn \"\".join(tokens).replace('_', ' ')\n",
    "\n",
    "\tdef save_pretrained(self, output_dir):\n",
    "\t\tpass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def convert_to_toks(sents):\n",
    "\n",
    "# \tsent_tokenizer = SentenceTokenizer()\n",
    "# \tword_tokenizer = WordTokenizer()\n",
    "\n",
    "# \tall_sents=[]\n",
    "\n",
    "# \tfor data in sents:\n",
    "# \t\ttext=data.lower()\n",
    "\n",
    "# \t\tsents=sent_tokenizer.tokenize(text)\n",
    "# \t\tfor sent in sents:\n",
    "# \t\t\ttokens=word_tokenizer.tokenize(sent)\n",
    "# \t\t\tfilt_toks=[]\n",
    "# \t\t\tfilt_toks.append(\"[CLS]\")\n",
    "# \t\t\tfor tok in tokens:\n",
    "# \t\t\t\tif tok != \"\":\n",
    "# \t\t\t\t\tfilt_toks.append(tok)\n",
    "# \t\t\tfilt_toks.append(\"[SEP]\")\n",
    "\n",
    "# \t\t\tall_sents.append(filt_toks)\n",
    "\n",
    "# \treturn all_sents\n",
    "\n",
    "# def df_to_toks(df, sent_column=\"sentence_ids\", word_column=\"words\"):\n",
    "\n",
    "# \tall_sents = []\n",
    "\n",
    "# \tgrouped = df.groupby(sent_column)\n",
    "\t\n",
    "# \tfor sent in grouped.groups:\n",
    "# \t\tsent_df = grouped.get_group(sent)\n",
    "\t\t\n",
    "# \t\ttokens = sent_df[word_column].values.tolist()\n",
    "\t\t\n",
    "# \t\tfilt_toks=[]\n",
    "\t\t\n",
    "# \t\tfilt_toks.append(\"[CLS]\")\n",
    "# \t\tfor tok in tokens:\n",
    "# \t\t\tif tok != \"\":\n",
    "# \t\t\t\tfilt_toks.append(tok)\n",
    "# \t\tfilt_toks.append(\"[SEP]\")\n",
    "\n",
    "# \t\tall_sents.append(filt_toks)\n",
    "\n",
    "# \treturn all_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ut_', 'vero_', 'ex_', 'litteris_', 'ad_', 'senatum_', 'referre', 'tur_', ',_', 'impetra', 'ri_', 'non_', 'potuit_', '._', 'hi_', 'omnes_', 'lingua_', ',_', 'institutis_', ',_', 'legibus_', 'inter_', 'se_', 'differunt_', '._', '\"_', 'namque_', 'tu_', 'sole', 'bas_', 'nuga', 's_', 'esse_', 'aliquid_', 'meas_', 'putare_', ',_', '\"_', 'ut_', 'obit', 'er_', 'emo', 'llia', 'm_', 'catull', 'um_', 'conter', 'rane', 'um_', 'meum_', '(_', 'agnosci', 's_', 'et_', 'hoc_', 'castr', 'ense_', 'verbum_', ')_', 'ille_', 'enim_', ',_', 'ut_', 'scis_', ',_', 'permutat', 'is_', 'prioribus_', 'syllab', 'is_', 'duri', 'uscul', 'um_', 'se_', 'fecit_', 'quam_', 'volebat_', 'existima', 'ri_', ',_', 'a_', 'vera', 'nio', 'lis_', 'suis_', 'et_', 'fabul', 'lis_', '._']\n"
     ]
    }
   ],
   "source": [
    "#load the tokenizer\n",
    "tokenizer = LatinTokenizer(text_encoder.SubwordTextEncoder('../latin-bert/models/subword_tokenizer_latin/latin.subword.encoder'))\n",
    "\n",
    "test_sentence = train.groupby('sentence').get_group(1)['word'].values.tolist()\n",
    "\n",
    "tokens = tokenizer.tokenize(test_sentence)\n",
    "\n",
    "print(tokens)\n",
    "\n",
    "#the output is unusual for huggingface, but it's in the vocab file this way so I leave it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5815 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/972 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3410 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def tokenize_adjust_labels(all_samples_per_split):\n",
    "\t\n",
    "\tpretokenized_samples = all_samples_per_split[\"tokens\"]\n",
    "\ttokenized_samples = tokenizer.tokenize(pretokenized_samples) #create wordpiece tokens\n",
    "\ttoken_ids = tokenizer.convert_tokens_to_ids(tokenized_samples) #to ids\n",
    "    #path both the tokens and the the token_ids, as the tokenids are on subwords\n",
    "\tpadded_tokenized_samples, padded_token_ids = tokenizer.pad_max_length_and_add_specials_tokens_also(tokenized_samples, token_ids) #pad and add special tokens\n",
    "\n",
    "\tall_samples_per_split['input_ids'] = padded_token_ids\n",
    "    \n",
    "\tall_samples_per_split['attention_mask'] = tokenizer.calculate_attention_masks(padded_token_ids)\n",
    "\tall_samples_per_split['wp_tokens'] = tokenized_samples\n",
    "\tall_samples_per_split['extra'] = padded_tokenized_samples\n",
    "\n",
    "\t#original\n",
    "\torig_labels = all_samples_per_split['tags']\n",
    "\n",
    "\n",
    "\t# logic to adjust labels, \n",
    "\tadjusted_labels = []\n",
    "\tlabel_idx = 0\n",
    "\t# print(len(pretokenized_samples))\n",
    "\n",
    "\tfor token in padded_tokenized_samples:\n",
    "\t\ttry:\n",
    "            #The tokenizer always treats punctuation as a separate token\n",
    "            #in most cases, this is not a problem as the punctuation is also seperately labeled in GWannotation, \n",
    "            #but there are a few exceptions\n",
    "            #next statement catches those\n",
    "            \n",
    "\t\t\tif token in ['[CLS]', '[SEP]', '[PAD]']:\n",
    "\t\t\t\tadjusted_labels.append(-100)\n",
    "                \n",
    "\t\t\telif re.match(r'\\w+[\\.\\,]', pretokenized_samples[label_idx]):\n",
    "\t\t\t\tif token != '._' and token != ',_':\n",
    "\t\t\t\t\tadjusted_labels.append(orig_labels[label_idx])\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tadjusted_labels.append(orig_labels[label_idx])\n",
    "\t\t\t\t\tlabel_idx += 1\n",
    "\t\t\n",
    "\t\t\telif token.endswith('_'):\n",
    "\t\t\t\tadjusted_labels.append(orig_labels[label_idx])\n",
    "\t\t\t\tlabel_idx += 1\n",
    "\n",
    "\t\t\telse:\n",
    "\t\t\t\tadjusted_labels.append(orig_labels[label_idx])\n",
    "\t\texcept IndexError:\n",
    "\t\t\ttry :\n",
    "\t\t\t\tif token in ['[CLS]', '[SEP]', '[PAD]']:\n",
    "\t\t\t\t\tadjusted_labels.append(-100)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tadjusted_labels.append(orig_labels[label_idx])\n",
    "\t\t\texcept IndexError:\n",
    "\t\t\t\tprint('HERE')\n",
    "\t\t\t\tprint(pretokenized_samples[:label_idx-1])\n",
    "\t\t\t\tprint(orig_labels[:label_idx-1])\n",
    "\t\t\t\tprint(token)\n",
    "\t\t\t\tprint(list(zip(padded_tokenized_samples, adjusted_labels)))\n",
    "\n",
    "\n",
    "\tall_samples_per_split['labels'] = adjusted_labels\n",
    "\n",
    "\ttry:\n",
    "\t\tassert len(adjusted_labels) == len(padded_tokenized_samples) == 256\n",
    "\texcept AssertionError:\n",
    "\t\tprint(all_samples_per_split)\n",
    "\n",
    "\n",
    "\treturn all_samples_per_split\n",
    "\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_adjust_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trainer test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1002322/3171414001.py:7: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"seqeval\")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "metric = load_metric(\"seqeval\")\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [idx2label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [idx2label[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    flattened_results = {\n",
    "        \"overall_precision\": results[\"overall_precision\"],\n",
    "        \"overall_recall\": results[\"overall_recall\"],\n",
    "        \"overall_f1\": results[\"overall_f1\"],\n",
    "        \"overall_accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "    return flattened_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install protobuf==3.20.* --user\n",
    "# model = AutoModelForTokenClassification.from_pretrained('../latin-bert/models')\n",
    "model = AutoModelForTokenClassification.from_pretrained('Herodotos_trained_lat_BERT_worked')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./fine_tune_bert_output\",\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_clear_list(temp, fixed, item):\n",
    "    temp.append(item)\n",
    "    fixed.append(int(np.mean(temp)))\n",
    "    temp.clear()\n",
    "\n",
    "\n",
    "def aggregate_ents(original_tokens, wp_tokens, preds, labels):\n",
    "    #THE FUNCTION WORKS\n",
    "    #Aggregates subword\n",
    "    try:\n",
    "        assert len(wp_tokens) == len(preds) and len(wp_tokens) == len(labels)\n",
    "    except AssertionError:\n",
    "        print('lenght tokens, predictions and labels are not equal')\n",
    "        print(wp_tokens)\n",
    "        \n",
    "    fixed_preds = []\n",
    "    fixed_labels = []\n",
    "    \n",
    "    temp_label = []\n",
    "    temp_pred = []\n",
    "    \n",
    "    for i in range(len(wp_tokens)-1):\n",
    "        if (wp_tokens[i+1] == '._') and (wp_tokens[i] != '._'):\n",
    "            \n",
    "            #check if word in orig_tokens is a \\w+[,.] token (M. or H,)\n",
    "            \n",
    "            #if the original token IS one of the special cases, treat current token as not a comp\n",
    "            if re.match(r'\\w+\\.', original_tokens[len(fixed_preds)]):\n",
    "                temp_label.append(labels[i])\n",
    "                temp_pred.append(preds[i])\n",
    "            \n",
    "            else:\n",
    "                extend_clear_list(temp_label, fixed_labels, labels[i])\n",
    "                extend_clear_list(temp_pred, fixed_preds, preds[i])\n",
    "                \n",
    "        elif wp_tokens[i+1] == ',_' and (wp_tokens[i] != ',_'):\n",
    "            \n",
    "            #check if word in orig_tokens is a \\w+[,.] token (M. or H,)\n",
    "            \n",
    "            #if the original token IS one of the special cases, treat current token as not a comp\n",
    "            if re.match(r'\\w+\\,', original_tokens[len(fixed_preds)]):\n",
    "                temp_label.append(labels[i])\n",
    "                temp_pred.append(preds[i])\n",
    "            \n",
    "            else:\n",
    "                extend_clear_list(temp_label, fixed_labels, labels[i])\n",
    "                extend_clear_list(temp_pred, fixed_preds, preds[i])\n",
    "            \n",
    "    \n",
    "        elif wp_tokens[i].endswith('_') and len(temp_label) == 0:\n",
    "            fixed_preds.append(preds[i])\n",
    "            fixed_labels.append(labels[i])\n",
    "            \n",
    "        elif wp_tokens[i].endswith('_'):\n",
    "            extend_clear_list(temp_label, fixed_labels, labels[i])\n",
    "            extend_clear_list(temp_pred, fixed_preds, preds[i])\n",
    "\n",
    "        else:\n",
    "            temp_label.append(labels[i])\n",
    "            temp_pred.append(preds[i])\n",
    "            \n",
    "            \n",
    "    fixed_preds.append(preds[len(wp_tokens)-1])\n",
    "    fixed_labels.append(labels[len(wp_tokens)-1])\n",
    "    \n",
    "            \n",
    "    try:        \n",
    "        assert len(original_tokens) == len(fixed_preds) and len(original_tokens) == len(fixed_labels)\n",
    "    except AssertionError:\n",
    "        original_tokens = original_tokens[:len(fixed_preds)]\n",
    "        try:\n",
    "            assert len(original_tokens) == len(fixed_preds) and len(original_tokens) == len(fixed_labels)\n",
    "        except AssertionError:\n",
    "            print('lenght of original tokens, aggregated predictions and labels are not equal')\n",
    "            print(f'''originals = {original_tokens} \\n \n",
    "                  tokenized = {wp_tokens}\\n\n",
    "                  predictions = {preds}\\n\n",
    "                  labels = {labels}\\n\n",
    "                  fixed_preds = {fixed_preds}\n",
    "                  fixed_labels = {fixed_labels}''')\n",
    "    \n",
    "    return original_tokens, fixed_preds, fixed_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tags, tokens, id, extra, wp_tokens. If tags, tokens, id, extra, wp_tokens are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 3410\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_dataset[\"test\"])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "\n",
    "true_predictions = [\n",
    "        [p for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(preds, predictions.label_ids)\n",
    "    ]\n",
    "    \n",
    "true_labels = [\n",
    "        [l for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(preds, predictions.label_ids)\n",
    "    ]\n",
    "\n",
    "tokens = tokenized_dataset['test']['extra']\n",
    "orig_tokens = tokenized_dataset['test']['tokens']\n",
    "ids = tokenized_dataset['test']['id']\n",
    "\n",
    "dct = {\n",
    "    'orig_tokens_all': [],\n",
    "    'agg_predictions_all': [],\n",
    "    'agg_labels_all': [],\n",
    "    'agg_ent_predictions_all': [],\n",
    "    'agg_ent_labels_all': [],\n",
    "    'all_ids': []\n",
    "}\n",
    "\n",
    "major_l = list(zip(ids, orig_tokens, tokens, true_predictions, true_labels))\n",
    "\n",
    "for idd, original_tokens, wp_tokens, preds, labels in major_l:\n",
    "    try:\n",
    "        wp_tokens = [token for token in wp_tokens if token not in ['[CLS]', '[PAD]', '[SEP]']] \n",
    "        orig_tokens, fixed_preds, fixed_labels = aggregate_ents(original_tokens, wp_tokens, preds, labels)\n",
    "        dct['orig_tokens_all'].append(orig_tokens)\n",
    "        dct['agg_predictions_all'].append(fixed_preds)\n",
    "        dct['agg_labels_all'].append(fixed_labels)\n",
    "        dct['agg_ent_predictions_all'].append([idx2label[pred] for pred in fixed_preds])\n",
    "        dct['agg_ent_labels_all'].append([idx2label[label] for label in fixed_labels])\n",
    "        dct['all_ids'].append([idd] * len(fixed_labels))\n",
    "    except AssertionError:\n",
    "        print('\\nOh no!\\n')\n",
    "        print(original_tokens)\n",
    "        print(wp_tokens)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GRP       0.87      0.71      0.78       354\n",
      "         LOC       0.77      0.71      0.74       305\n",
      "        PERS       0.85      0.83      0.84       849\n",
      "\n",
      "   micro avg       0.84      0.78      0.81      1508\n",
      "   macro avg       0.83      0.75      0.79      1508\n",
      "weighted avg       0.84      0.78      0.81      1508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "print(classification_report(dct['agg_ent_labels_all'], dct['agg_ent_predictions_all']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnested_dct = {\n",
    "    key: sum(value, []) for key, value in dct.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31788\n",
      "31788\n",
      "31788\n",
      "31788\n",
      "31788\n",
      "31788\n"
     ]
    }
   ],
   "source": [
    "for key, value in unnested_dct.items():\n",
    "    print(len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3410\n",
      "3410\n",
      "3410\n",
      "3410\n",
      "3410\n",
      "3410\n"
     ]
    }
   ],
   "source": [
    "for key, value in dct.items():\n",
    "    print(len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nam',\n",
       " 'nos',\n",
       " 'quoque',\n",
       " 'tam',\n",
       " 'numerosum',\n",
       " 'agmen',\n",
       " 'reorum',\n",
       " 'ita',\n",
       " 'demum',\n",
       " 'videbamus',\n",
       " 'posse',\n",
       " 'superari',\n",
       " ',',\n",
       " 'si',\n",
       " 'per',\n",
       " 'singulos',\n",
       " 'carperetur',\n",
       " '.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct['orig_tokens_all'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(unnested_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig_tokens_all</th>\n",
       "      <th>agg_predictions_all</th>\n",
       "      <th>agg_labels_all</th>\n",
       "      <th>agg_ent_predictions_all</th>\n",
       "      <th>agg_ent_labels_all</th>\n",
       "      <th>all_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>timere</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>CW_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caesarem</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B-PERS</td>\n",
       "      <td>B-PERS</td>\n",
       "      <td>CW_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ereptis</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>CW_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ab</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>CW_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>CW_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31783</th>\n",
       "      <td>si</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>PlinyYounger_1335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31784</th>\n",
       "      <td>per</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>PlinyYounger_1335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31785</th>\n",
       "      <td>singulos</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>PlinyYounger_1335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31786</th>\n",
       "      <td>carperetur</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>PlinyYounger_1335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31787</th>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>PlinyYounger_1335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31788 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      orig_tokens_all  agg_predictions_all  agg_labels_all  \\\n",
       "0              timere                    0               0   \n",
       "1            Caesarem                    1               1   \n",
       "2             ereptis                    0               0   \n",
       "3                  ab                    0               0   \n",
       "4                  eo                    0               0   \n",
       "...               ...                  ...             ...   \n",
       "31783              si                    0               0   \n",
       "31784             per                    0               0   \n",
       "31785        singulos                    0               0   \n",
       "31786      carperetur                    0               0   \n",
       "31787               .                    0               0   \n",
       "\n",
       "      agg_ent_predictions_all agg_ent_labels_all            all_ids  \n",
       "0                           O                  O              CW_11  \n",
       "1                      B-PERS             B-PERS              CW_11  \n",
       "2                           O                  O              CW_11  \n",
       "3                           O                  O              CW_11  \n",
       "4                           O                  O              CW_11  \n",
       "...                       ...                ...                ...  \n",
       "31783                       O                  O  PlinyYounger_1335  \n",
       "31784                       O                  O  PlinyYounger_1335  \n",
       "31785                       O                  O  PlinyYounger_1335  \n",
       "31786                       O                  O  PlinyYounger_1335  \n",
       "31787                       O                  O  PlinyYounger_1335  \n",
       "\n",
       "[31788 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pricie/marijkeb/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-GRP       0.88      0.72      0.79       354\n",
      "       B-LOC       0.80      0.72      0.76       305\n",
      "      B-PERS       0.88      0.84      0.86       849\n",
      "       I-GRP       0.00      0.00      0.00         3\n",
      "       I-LOC       0.25      0.25      0.25         8\n",
      "      I-PERS       0.78      0.91      0.84        99\n",
      "           O       0.99      1.00      1.00     30170\n",
      "\n",
      "    accuracy                           0.99     31788\n",
      "   macro avg       0.66      0.63      0.64     31788\n",
      "weighted avg       0.99      0.99      0.99     31788\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(df.agg_ent_labels_all, df.agg_ent_predictions_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['all_ids'].apply(lambda x: x.split('_')[0])\n",
    "df['sentence'] = df['all_ids'].apply(lambda x: x.split('_')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ovid            17102\n",
       "GW               7452\n",
       "PlinyElder       4188\n",
       "PlinyYounger     2454\n",
       "CW                592\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['domain'] = df['text'].apply(lambda x: 'IN' if x != 'Ovid' else 'OUT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns = {'orig_tokens_all': 'token',\n",
    "                    'agg_ent_predictions_all': 'predictions',\n",
    "                    'agg_ent_labels_all': 'labels',\n",
    "                    'all_ids': 'sentence_ids',\n",
    "                    'agg_predictions_all': 'prediction_id',\n",
    "                    'agg_labels_all': 'label_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['token', 'label_id', 'prediction_id', 'labels', 'predictions', 'sentence_ids', 'text', 'sentence', 'domain']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>label_id</th>\n",
       "      <th>prediction_id</th>\n",
       "      <th>labels</th>\n",
       "      <th>predictions</th>\n",
       "      <th>sentence_ids</th>\n",
       "      <th>text</th>\n",
       "      <th>sentence</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>timere</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>CW_11</td>\n",
       "      <td>CW</td>\n",
       "      <td>11</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caesarem</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B-PERS</td>\n",
       "      <td>B-PERS</td>\n",
       "      <td>CW_11</td>\n",
       "      <td>CW</td>\n",
       "      <td>11</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ereptis</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>CW_11</td>\n",
       "      <td>CW</td>\n",
       "      <td>11</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ab</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>CW_11</td>\n",
       "      <td>CW</td>\n",
       "      <td>11</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>CW_11</td>\n",
       "      <td>CW</td>\n",
       "      <td>11</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31783</th>\n",
       "      <td>si</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>PlinyYounger_1335</td>\n",
       "      <td>PlinyYounger</td>\n",
       "      <td>1335</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31784</th>\n",
       "      <td>per</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>PlinyYounger_1335</td>\n",
       "      <td>PlinyYounger</td>\n",
       "      <td>1335</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31785</th>\n",
       "      <td>singulos</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>PlinyYounger_1335</td>\n",
       "      <td>PlinyYounger</td>\n",
       "      <td>1335</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31786</th>\n",
       "      <td>carperetur</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>PlinyYounger_1335</td>\n",
       "      <td>PlinyYounger</td>\n",
       "      <td>1335</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31787</th>\n",
       "      <td>.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>PlinyYounger_1335</td>\n",
       "      <td>PlinyYounger</td>\n",
       "      <td>1335</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31788 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            token  label_id  prediction_id  labels predictions  \\\n",
       "0          timere         0              0       O           O   \n",
       "1        Caesarem         1              1  B-PERS      B-PERS   \n",
       "2         ereptis         0              0       O           O   \n",
       "3              ab         0              0       O           O   \n",
       "4              eo         0              0       O           O   \n",
       "...           ...       ...            ...     ...         ...   \n",
       "31783          si         0              0       O           O   \n",
       "31784         per         0              0       O           O   \n",
       "31785    singulos         0              0       O           O   \n",
       "31786  carperetur         0              0       O           O   \n",
       "31787           .         0              0       O           O   \n",
       "\n",
       "            sentence_ids          text sentence domain  \n",
       "0                  CW_11            CW       11     IN  \n",
       "1                  CW_11            CW       11     IN  \n",
       "2                  CW_11            CW       11     IN  \n",
       "3                  CW_11            CW       11     IN  \n",
       "4                  CW_11            CW       11     IN  \n",
       "...                  ...           ...      ...    ...  \n",
       "31783  PlinyYounger_1335  PlinyYounger     1335     IN  \n",
       "31784  PlinyYounger_1335  PlinyYounger     1335     IN  \n",
       "31785  PlinyYounger_1335  PlinyYounger     1335     IN  \n",
       "31786  PlinyYounger_1335  PlinyYounger     1335     IN  \n",
       "31787  PlinyYounger_1335  PlinyYounger     1335     IN  \n",
       "\n",
       "[31788 rows x 9 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('errors_test_set_herodotos_FINAL.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check for match with csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_csv('./data/Latin_NER_test.csv', index_col=0)\n",
    "\n",
    "#the following is necessary because the eval.csv is not in ascending sentence order and the json is\n",
    "grouped = val.groupby('sentence')\n",
    "\n",
    "val2 = pd.DataFrame(columns = ['word', 'tag', 'sentence'])\n",
    "\n",
    "for name, group in grouped:\n",
    "    val2 = pd.concat([val2, group])\n",
    "\n",
    "\n",
    "assert val2['tag'].values.tolist() == unnested_dct['agg_ent_labels_all']\n",
    "assert val2['word'].values.tolist() == unnested_dct['orig_tokens_all']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
